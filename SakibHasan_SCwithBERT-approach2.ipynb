{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!/opt/conda/bin/python3.7 -m pip install --upgrade pip","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Installing Dependencies(if needed)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# A dependency of the preprocessing for BERT inputs\n!pip install -q tensorflow-text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tf-models-official","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport shutil\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as text\nfrom official.nlp import optimization  # to create AdamW optmizer\n\nimport matplotlib.pyplot as plt\n\ntf.get_logger().setLevel('ERROR')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow-gpu","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking GPU Availability"},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.test.is_gpu_available(True) # returns True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n\ndataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url,\n                                  untar=True, cache_dir='.',\n                                  cache_subdir='')\n\ndataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n\ntrain_dir = os.path.join(dataset_dir, 'train')\n\nprint(train_dir)\n\n# remove unused folders to make it easier to load the data\nremove_dir = os.path.join(train_dir, 'unsup')\nshutil.rmtree(remove_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\nbatch_size = 32 #could be changed\nseed = 42   #could be changed\n\n\n#preprocessing the data using TensorFlow\n\n#creating training set\nraw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n    'aclImdb/train',\n    batch_size=batch_size,\n    validation_split=0.2,\n    subset='training',\n    seed=seed)\n\nclass_names = raw_train_ds.class_names\ntrain_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\n#creating validation set\nval_ds = tf.keras.preprocessing.text_dataset_from_directory(\n    'aclImdb/train',\n    batch_size=batch_size,\n    validation_split=0.2,\n    subset='validation',\n    seed=seed)\n\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\n#creating testing set\ntest_ds = tf.keras.preprocessing.text_dataset_from_directory(\n    'aclImdb/test',\n    batch_size=batch_size)\n\ntest_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for text_batch, label_batch in train_ds.take(1):\n  for i in range(3):\n    print(f'Review: {text_batch.numpy()[i]}')\n    label = label_batch.numpy()[i]\n    print(f'Label : {label} ({class_names[label]})')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Selecting BERT Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8' \n\nmap_name_to_handle = {\n    'bert_en_uncased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n    'bert_en_cased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n    'bert_multi_cased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n    'albert_en_base':\n        'https://tfhub.dev/tensorflow/albert_en_base/2',\n    'electra_small':\n        'https://tfhub.dev/google/electra_small/2',\n    'electra_base':\n        'https://tfhub.dev/google/electra_base/2',\n    'experts_pubmed':\n        'https://tfhub.dev/google/experts/bert/pubmed/2',\n    'experts_wiki_books':\n        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n    'talking-heads_base':\n        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n}\n\nmap_model_to_preprocess = {\n    'bert_en_uncased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'bert_en_cased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/2',\n    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'bert_multi_cased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/2',\n    'albert_en_base':\n        'https://tfhub.dev/tensorflow/albert_en_preprocess/2',\n    'electra_small':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'electra_base':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'experts_pubmed':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'experts_wiki_books':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'talking-heads_base':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n}\n\ntfhub_handle_encoder = map_name_to_handle[bert_model_name]\ntfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n\nprint(f'BERT model selected           : {tfhub_handle_encoder}')\nprint(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The Preprocessing Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check if the preprocess model works as expected"},{"metadata":{"trusted":true},"cell_type":"code","source":"text_test = ['this is such an amazing movie!']\ntext_preprocessed = bert_preprocess_model(text_test)\n\nprint(f'Keys       : {list(text_preprocessed.keys())}')\nprint(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\nprint(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\nprint(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\nprint(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using the BERT model"},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_model = hub.KerasLayer(tfhub_handle_encoder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_results = bert_model(text_preprocessed)\n\nprint(f'Loaded BERT: {tfhub_handle_encoder}')\nprint(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\nprint(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\nprint(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\nprint(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Your Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_classifier_model():\n  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n  encoder_inputs = preprocessing_layer(text_input)\n  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n  outputs = encoder(encoder_inputs)\n  net = outputs['pooled_output']\n  net = tf.keras.layers.Dropout(0.1)(net)\n  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n  return tf.keras.Model(text_input, net)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_model = build_classifier_model()\nbert_raw_result = classifier_model(tf.constant(text_test))\nprint(tf.sigmoid(bert_raw_result))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(classifier_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\nmetrics = tf.metrics.BinaryAccuracy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 5\nsteps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\nnum_train_steps = steps_per_epoch * epochs\nnum_warmup_steps = int(0.1*num_train_steps)\n\ninit_lr = 3e-5\noptimizer = optimization.create_optimizer(init_lr=init_lr,\n                                          num_train_steps=num_train_steps,\n                                          num_warmup_steps=num_warmup_steps,\n                                          optimizer_type='adamw')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the BERT model and training"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_model.compile(optimizer=optimizer,\n                         loss=loss,\n                         metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Training model with {tfhub_handle_encoder}')\nhistory = classifier_model.fit(x=train_ds,\n                               validation_data=val_ds,\n                               epochs=epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy = classifier_model.evaluate(test_ds)\n\nprint(f'Loss: {loss}')\nprint(f'Accuracy: {accuracy}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performance Report\n\nClassification report with Negative and Positive classes, then printing the Confusion matrix after getting the predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## References\nhttps://www.tensorflow.org/tutorials/text/classify_text_with_bert\n"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}